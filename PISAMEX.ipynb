{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Science 180\n",
    "\n",
    "\n",
    "\n",
    "![Alt text](http://thegeektown.com/wp-content/uploads/2015/03/data-scientist.jpg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "An adventure through 15 dimensions of data wrangling, visualization and modeling at mind-bending speeds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In a world with too much data sitting around and not enough insight, to whom will we turn for help?\n",
    "\n",
    "![Alt](http://nextviewventures.com/blog/wp-content/uploads/2014/07/control-content-marekting-for-startups.jpg)\n",
    "\n",
    "##YOU!    (Neo was busy...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### You must learn how to wrangle data in the next few hours in order to save the education system. If you fail, we're all doomed...\n",
    "\n",
    "### You have been given a dataset of test results and metadata, along with a laptop computer. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Good luck, everything depends on you.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###Where do we begin? \n",
    "\n",
    "\n",
    "###You know Python right? It does data stuff, right? OK, let's get started then.\n",
    "\n",
    "###First thing to figure out is how to get the data files on your machine into Python in the first place.\n",
    "\n",
    "\n",
    "###You've heard of this library called Pandas from another Agent -- it once saved them in a pinch. Lacking any better ideas, let's open up an editor and see if we can't at least cross the starting line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Reading data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "exam_data = pd.read_csv('data/PISA2009_Scored_Tests_MEX.csv')\n",
    "bio_data = pd.read_csv('data/PISA2009_Questionnaire_MEX.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###What did that just do? \n",
    "\n",
    "\n",
    "\n",
    "We called \"read_csv\", which presumably reads CSV files... and does what with them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##pd.read_csv does a magical thing \n",
    "\n",
    "\n",
    "It reads a CSV file into a DataFrame. \n",
    "\n",
    "DataFrames are mystical creatures in Data Science. \n",
    "\n",
    "Popularized by R, they provide a standardized MATRIX-style format for interacting with your data. Most data can fit into this row and column format: financial transactions, iPhone app user records, medical histories, etc.\n",
    "\n",
    "(And you thought the Matrix references were just for fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt](http://www.bigdataexaminer.com/wp-content/uploads/2014/12/screen-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##Since you were wondering\n",
    "\n",
    "##Pandas has support for many formats\n",
    "\n",
    "CSV, Text (tab separated, pipe separated, etc.), Excel, JSON, HTML, SQL, Stuff copied to your clipboard, HDF5..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hold up. What's really going on with these DataFrames?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Two data structures: Series and DataFrame\n",
    "\n",
    "###Series\n",
    "Think of this as one column of your data - one data type.\n",
    "\n",
    "### DataFrame\n",
    "All of the columns in your data. Mixed data types. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Many Series can be combined and represented as a DataFrame object.\n",
    "\n",
    "#A DataFrame can be represented as many Series objects. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#Pandas provides tons of functions to:\n",
    "\n",
    "###slice, dice, merge, join, group by, select, append, find, transform, sort, reverse, pivot and anything else you want to do\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#... for both Series and DataFrames. \n",
    "\n",
    "Most functions are designed to work with either type or even combinations of the two, just like you would intuitively expect:\n",
    "\n",
    "i.e. A concat function can contatenate arbitrary combinations of 0 to n Series and DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#So you know a bit about DataFrames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "exam_data = pd.read_csv('data/PISA2009_Scored_Tests_MEX.csv')\n",
    "bio_data = pd.read_csv('data/PISA2009_Questionnaire_MEX.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fine. What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Exploratory Data Analysis. \n",
    "\n",
    "What the hell is in those files anyway?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it look like test data should? \n",
    "\n",
    "Is it completely empty? Full? Lots of missing values and NaNs?\n",
    "\n",
    "What are in the rows? columns?\n",
    "\n",
    "Does it have appropriate features? (characteristics common to records belonging to a dataset)\n",
    "\n",
    "###It's impossible to make good decisions moving forward until we know more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can just output the entire dataframe to the console, but that doesn't scale beyond a couple hundred rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<pre>\n",
    "In [1]: df = DataFrame(np.random.randn(10, 4))\n",
    "\n",
    "In [2]: df\n",
    "Out[2]: \n",
    "          0         1         2         3\n",
    "0  0.469112 -0.282863 -1.509059 -1.135632\n",
    "1  1.212112 -0.173215  0.119209 -1.044236\n",
    "2 -0.861849 -2.104569 -0.494929  1.071804\n",
    "3  0.721555 -0.706771 -1.039575  0.271860\n",
    "4 -0.424972  0.567020  0.276232 -1.087401\n",
    "5 -0.673690  0.113648 -1.478427  0.524988\n",
    "6  0.404705  0.577046 -1.715002 -1.039268\n",
    "7 -0.370647 -1.157892 -1.344312  0.844885\n",
    "8  1.075770 -0.109050  1.643563 -1.469388\n",
    "9  0.357021 -0.674600 -1.776904 -0.968914\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Pandas gives us a number of tools: \n",
    "\n",
    "<br>\n",
    "    \n",
    "    .head(n)\n",
    "    .info()\n",
    "    .describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "exam_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "exam_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "exam_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#We have two files, and both of them have a feature named 'Student ID 5-digit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#Using this unique ID as our guide, we can match the exam scores and biographical data for a single student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#This task comes up a lot in data wrangling, since different kinds of data will be stored in different data stores. Often one of the first steps is to combine the relevant sections from each repository of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "useless = {\n",
    "    u' Version of cognitive database and date of release',\n",
    "    u'3-character country code ',\n",
    "    u'Adjudicated sub-region',\n",
    "}\n",
    "\n",
    "not_questions = {u'Booklet', \n",
    "                 u'School ID 5-digit', \n",
    "                 u'Student ID 5-digit',\n",
    "                 u'OECD country',\n",
    "                 u'Country code ISO 3-digit',}\n",
    "\n",
    "score_mapping = {\n",
    "    'Score 0': 0,\n",
    "    'Score 1': 1,\n",
    "    'Score 2': 2,\n",
    "    'Not reached': 0,\n",
    "}\n",
    "\n",
    "questions = set(exam_data.columns) - not_questions - useless\n",
    "\n",
    "for question in questions:\n",
    "    exam_data[question] = exam_data[question].map(score_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "math_qs = {q for q in questions if q.startswith('MATH')}\n",
    "read_qs = {q for q in questions if q.startswith('READ')}\n",
    "scie_qs = {q for q in questions if q.startswith('SCIE')}\n",
    "    \n",
    "totals = exam_data[list(questions)].sum(axis=1)\n",
    "math_score = exam_data[list(math_qs)].sum(axis=1)\n",
    "read_score = exam_data[list(read_qs)].sum(axis=1)\n",
    "scie_score = exam_data[list(scie_qs)].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Let's do a merge to get our data into a single managable spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame({'Total Score': totals, \n",
    "                         'Math Score': math_score, \n",
    "                         'Reading Score': read_score, \n",
    "                         'Science Score': scie_score,\n",
    "                         'Student ID 5-digit': exam_data['Student ID 5-digit']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.merge(score_df, bio_data, on='Student ID 5-digit')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#Now we can pick any feature (read: column) and get information on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data['Reading Enjoyment Time'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Particularly important for later\n",
    "\n",
    "Looking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Now that you can load data and look at it\n",
    "\n",
    "#It's time for exercise #1 \n",
    "\n",
    "Go to https://github.com/dsakagi/odsc-pisa to clone the code for this talk\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<pre>\n",
    "$ mkvirtualenv odsc\n",
    "$ git clone https://github.com/dsakagi/odsc-pisa.git\n",
    "$ cd odsc-pisa\n",
    "$ mkdir data\n",
    "$ make\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#But what about relationships between variables?\n",
    "\n",
    "We could look at sets of rows and see what occurs together, or compute statistics of co-occurrence ---> but still impossible to get a comprehensive view quickly.\n",
    "\n",
    "What can we try?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#Let's do some plots!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#A quick aside.\n",
    "\n",
    "\n",
    "\n",
    "iPython Notebooks (like this one) are great tools for making Python code and outputs human-readable. To get your plots to render within the notebook use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Two plotting weapons\n",
    "\n",
    "###Matplotlib\n",
    "\n",
    "- The historical go-to for plotting\n",
    "- allows lots of fine-grained control\n",
    "- built with numpy in mind (Numpy and its cousin Scipy are the number-crunching go-to's in Python)\n",
    "\n",
    "###Seaborn\n",
    "\n",
    "- Expressive power\n",
    "- built with pandas in mind\n",
    "- trendy newcomer, but gaining a loyal following"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We will mainly use seaborn examples in this presentation. It's very intuitive and powerful to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Scatterplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "View relationship between two continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot(data['Index of economic, social and cultural status (WLE)'], \n",
    "              data['Home Possessions'], kind=\"hex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this dataset, several variables can stand as proxies for socio-economic status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Histogram\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Visualize distribution of continuous data.\n",
    "\n",
    "\n",
    "- Visualize distribution across categorical levels.\n",
    "\n",
    "- Can plot two histograms on top of each other\n",
    "\n",
    "- See the effects of the variable on the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "groups = data.groupby('Sex').groups\n",
    "for key, row_ids in groups.iteritems():\n",
    "    pylab.hist(data['Total Score'][row_ids].values,\n",
    "               normed=True,\n",
    "               bins=np.linspace(0, 70, 11),\n",
    "               alpha=0.35,\n",
    "               label=str(key))\n",
    "pylab.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###Doesn't work as well for more than two levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "groups = data.groupby('Grade').groups\n",
    "for key, row_ids in groups.iteritems():\n",
    "    pylab.hist(data['Total Score'][row_ids].values,\n",
    "               normed=True,\n",
    "               bins=np.linspace(0, 70, 11),\n",
    "               alpha=0.35,\n",
    "               label=str(key))\n",
    "pylab.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Violin Plots work better for comparing several distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "nonnull_subset = data['Total Score'].notnull()\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(data['Total Score'][nonnull_subset], \n",
    "               data['Father  <Highest Schooling>'][nonnull_subset], \n",
    "               inner='box',\n",
    "               bw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##Alternatively, use `FacetGrid`\n",
    "###Visualize the distributions for different settings of two variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, row=\"Sex\", col=\"At Home - Mother\", margin_titles=True)\n",
    "bins = np.linspace(0, 67, 13)\n",
    "g.map(plt.hist, \"Total Score\", color=\"steelblue\", bins=bins, lw=0, normed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###If distribution not required, try factor plot to get a simpler comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(\"At Home - Father\", \"Total Score\", \"Sex\",\n",
    "                    data=data, kind=\"bar\",\n",
    "                    size=6, palette=\"muted\", dropna=True)\n",
    "g.despine(left=True)\n",
    "g.set_ylabels(\"Mean Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.factorplot(\"Sex\", \"Total Score\", \"Sex\",\n",
    "                   row=\"At Home - Mother\",\n",
    "                   col=\"At Home - Father\",\n",
    "                   data=data, kind=\"bar\",\n",
    "                   size=6, palette=\"muted\",\n",
    "                   dropna=True)\n",
    "g.despine(left=True)\n",
    "g.set_ylabels(\"Mean Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Heatmaps are a visual tool to look at the distribution of observations _across_ settings of two variables (as opposed to _within_ a setting like `FacetGrid`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ptable = pd.pivot_table(\n",
    "    data, \n",
    "    values='Total Score', \n",
    "    index='Like Read - Fiction', \n",
    "    columns='Like Read - Non-fiction books')\n",
    "sns.heatmap(ptable, annot=True, fmt=\"f\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "###Not very useful if not in order..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###Heatmaps - Round 2\n",
    "####Effects of variables over a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "display_order = [\n",
    "    u'Never or almost never',\n",
    "    u'A few times a year', \n",
    "    u'About once a month',                   \n",
    "    u'Several times a month', \n",
    "    u'Several times a week'\n",
    "]\n",
    "display_table = ptable[display_order].reindex(reversed(display_order))\n",
    "sns.heatmap(display_table,\n",
    "            annot=True, \n",
    "            fmt=\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###Pivot tables can do other aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "count_table = pd.pivot_table(\n",
    "    data, \n",
    "    values='Total Score', \n",
    "    index='Like Read - Fiction', \n",
    "    columns='Like Read - Non-fiction books',\n",
    "    aggfunc=np.count_nonzero)\n",
    "\n",
    "sns.heatmap(count_table[display_order].reindex(reversed(display_order)), annot=True, fmt=\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Scatterplot\n",
    "\n",
    "What is the relationship between X and Y? (If any!)\n",
    "\n",
    "Positive, Negative, Linear, Non-linear...\n",
    "\n",
    "Are there clusters of similar observations?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "some_sample = random.sample(data.index, 1000)\n",
    "sns.lmplot(\"Total Score\", \n",
    "           'Index of economic, social and cultural status (WLE)', \n",
    "           data.ix[some_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Why plot just a subset of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.lmplot(\"Total Score\", \n",
    "           'Index of economic, social and cultural status (WLE)', \n",
    "           data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_data = data['Reading Enjoyment Time'].apply(lambda x: isinstance(x, basestring) and x.startswith('I don'))\n",
    "reading_enjoyment = data['Reading Enjoyment Time'].copy()\n",
    "reading_enjoyment[bad_data] = 'No Joy'\n",
    "\n",
    "time_x_fiction = pd.pivot_table(\n",
    "    data, \n",
    "    values='Total Score', \n",
    "    index='Like Read - Fiction', \n",
    "    columns=reading_enjoyment)\n",
    "\n",
    "col_order = [\n",
    "    'No Joy', \n",
    "    '30 minutes or less a day', \n",
    "    'Between 30 and 60 minutes',\n",
    "    '1 to 2 hours a day',\n",
    "    'More than 2 hours a day'\n",
    "]\n",
    "\n",
    "row_order = [\n",
    "    'Several times a week',\n",
    "    'Several times a month',\n",
    "    'About once a month',\n",
    "    'A few times a year',\n",
    "    'Never or almost never',\n",
    "]\n",
    "\n",
    "display_table = time_x_fiction[col_order].reindex(row_order)\n",
    "sns.heatmap(display_table, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_data = data['Reading Enjoyment Time'].apply(lambda x: isinstance(x, basestring) and x.startswith('I don'))\n",
    "reading_enjoyment = data['Reading Enjoyment Time'].copy()\n",
    "reading_enjoyment[bad_data] = 'No Joy'\n",
    "\n",
    "time_x_nonfiction = pd.pivot_table(\n",
    "    data, \n",
    "    values='Total Score', \n",
    "    index='Like Read - Non-fiction books', \n",
    "    columns=reading_enjoyment)\n",
    "\n",
    "col_order = [\n",
    "    'No Joy', \n",
    "    '30 minutes or less a day', \n",
    "    'Between 30 and 60 minutes',\n",
    "    '1 to 2 hours a day',\n",
    "    'More than 2 hours a day'\n",
    "]\n",
    "\n",
    "row_order = [\n",
    "    'Several times a week',\n",
    "    'Several times a month',\n",
    "    'About once a month',\n",
    "    'A few times a year',\n",
    "    'Never or almost never',\n",
    "]\n",
    "\n",
    "non_f_display_table = time_x_nonfiction[col_order].reindex(row_order)\n",
    "sns.heatmap(non_f_display_table, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_reading = 'Online Reading'\n",
    "key_score = 'Total Score'\n",
    "key_econ = 'Index of economic, social and cultural status (WLE)'\n",
    "\n",
    "data_reading = data[key_reading]\n",
    "data_score = data[key_score]\n",
    "data_econ = data[key_econ]\n",
    "\n",
    "reading_bins = np.linspace(np.min(data_reading), np.max(data_reading), 5)\n",
    "econ_bins = np.linspace(np.min(data_econ), np.max(data_econ), 5)\n",
    "\n",
    "to_pivot = pd.DataFrame({\n",
    "    key_reading: np.digitize(data_reading, \n",
    "                             bins=reading_bins),\n",
    "    key_econ: np.digitize(data_econ,\n",
    "                          bins=econ_bins),\n",
    "    key_score: data_score\n",
    "})\n",
    "\n",
    "ptable = pd.pivot_table(\n",
    "    to_pivot, \n",
    "    values=key_score,\n",
    "    index=key_reading,\n",
    "    columns=key_econ,\n",
    "    aggfunc=np.mean)\n",
    "ptable.columns = pd.Series(map(str, econ_bins), name='Economic Status')\n",
    "ptable.index = pd.Series(map(str, reading_bins), name='Reading Values')\n",
    "\n",
    "sns.heatmap(ptable, annot=False, fmt=\"f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Now for exercise 2\n",
    "\n",
    "Use your new found plotting knowledge to make a few of your own plots in seaborn. Use some of the many variables in the dataset that we haven't shown to find interesting hidden relationships.\n",
    "\n",
    "When you find something cool, call us over!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scikit-Learn\n",
    "\n",
    "# Widely used machine learning package\n",
    "\n",
    "- Classification Models\n",
    "- Regression Models\n",
    "- Clustering techniques\n",
    "- Dimensionality Reduction\n",
    "- Preprocessing\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```\n",
    "$ pip install scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##Experimental Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##Build a model that is useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can only build model on data that has a known output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our data has missing values in the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Today, we'll drop those observations. \n",
    "\n",
    "Just as a note, sometimes this isn't a good thing to do (think of a clinical study...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model_data = data[data['Total Score'].notnull()]\n",
    "target = model_data.pop('Total Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Avoiding overfitting\n",
    "- Need to keep data we train on from data we validate on\n",
    "- Otherwise the results will be overly optmistic\n",
    "- ... and ultimately, the model will perform poorly on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation\n",
    "\n",
    "(train_data, \n",
    " test_data, \n",
    " train_target, \n",
    " test_target) = sklearn.cross_validation.train_test_split(\n",
    "    model_data, target, test_size=0.2, random_state=1337\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "####Today we will use simple train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "####Recommend using multiple cross-validation folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##Variable Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###Most statistical models require numeric encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "###Many will choke on missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "###Need some massaging before fitting a statistical learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "import sklearn.feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data['Repeat <ISCED 1>'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data['Mother  <Highest Schooling>'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "encoder = DictVectorizer(sparse=False)\n",
    "\n",
    "our_categ_vars = [\n",
    "    'Repeat <ISCED 1>',\n",
    "    'Mother  <Highest Schooling>',\n",
    "    'Possessions Internet',\n",
    "    'Online - Reading Emails',\n",
    "    'Sex',\n",
    "    'Reading Tasks - Memorise text',\n",
    "]\n",
    "\n",
    "vardata = train_data[our_categ_vars].fillna('MISSING')\n",
    "encoder.fit(vardata.to_dict(orient='records'))\n",
    "\n",
    "train_catdata = encoder.transform(vardata.to_dict(orient='records'))\n",
    "\n",
    "test_vardata = test_data[our_categ_vars].fillna('MISSING')\n",
    "test_catdata = encoder.transform(\n",
    "    test_data[our_categ_vars].to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##Missing values in numeric columns\n",
    "\n",
    "###We will impute with the median value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy='median')\n",
    "\n",
    "our_num_vars = [\n",
    "    'Grade',\n",
    "    'Home Possessions',\n",
    "    'Joy/Like Reading',\n",
    "    'Diversity reading',\n",
    "    'No of ALL <class period> a week',\n",
    "    'Reading for School: Traditional literature courses',\n",
    "    'Min in <class period> for <Maths>'\n",
    "]\n",
    "\n",
    "numdata = train_data[our_num_vars]\n",
    "imputer.fit(numdata)\n",
    "\n",
    "train_numdata = imputer.transform(numdata)\n",
    "test_numdata = imputer.transform(test_data[our_num_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now, we put our training data back together again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_this = np.hstack([train_numdata, train_catdata])\n",
    "test_this = np.hstack([test_numdata, test_catdata])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##Finally, ready to build a model\n",
    "###Linear Regression is a sensible first choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(train_this, train_target)\n",
    "\n",
    "lr_predictions = pd.Series(lr.predict(test_this),\n",
    "                           name='Linear Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p_df = pd.DataFrame({'Prediction': lr_predictions,\n",
    "                     'Actual': test_target.values})\n",
    "\n",
    "pylab.figure(figsize=(10, 10))\n",
    "sns.jointplot('Actual', 'Prediction', data=p_df, kind=\"hex\", color=sns.color_palette()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##Was our model any good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "test_metrics = {\n",
    "    'Explained Variance': metrics.explained_variance_score,\n",
    "    'MAE': metrics.mean_absolute_error,\n",
    "    'MSE': metrics.mean_squared_error,\n",
    "    'MedAE': metrics.median_absolute_error,\n",
    "    'R2': metrics.r2_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def metrics_report(*predictions):\n",
    "    records = []\n",
    "    for prediction_set in predictions:\n",
    "        record = {'name': prediction_set.name}\n",
    "        for metric_name in sorted(test_metrics.keys()):\n",
    "            metric_func = test_metrics[metric_name]\n",
    "            record[metric_name] = metric_func(test_target, prediction_set)\n",
    "        records.append(record)\n",
    "    frame = pd.DataFrame.from_records(records).set_index('name')\n",
    "    return frame\n",
    "        \n",
    "metrics_report(lr_predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##These numbers don't really tell you if a model is good\n",
    "###Not by themselves, at least\n",
    "###Keep them in mind while we do more modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##Now, just for a baseline\n",
    "###Let's look at the mean and median predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mean_response = np.mean(train_target)\n",
    "mean_predictions = pd.Series(np.ones_like(test_target) * mean_response,\n",
    "                             name='Mean Response')\n",
    "\n",
    "median_response = np.median(train_target)\n",
    "median_predictions = pd.Series(np.ones_like(test_target) * median_response,\n",
    "                               name='Median Response')\n",
    "\n",
    "metrics_report(mean_predictions, \n",
    "               median_predictions, \n",
    "               lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##Ordinary linear regression is boring\n",
    "### Let's try something more exotic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "estimator = linear_model.ElasticNet()\n",
    "\n",
    "parameters = {\n",
    "    'alpha': np.linspace(0.1, 2, 10, endpoint=True),\n",
    "    'l1_ratio': np.linspace(0, 1, 10, endpoint=True)\n",
    "}\n",
    "\n",
    "enet = GridSearchCV(estimator, parameters, verbose=2, n_jobs=4)\n",
    "enet.fit(train_this, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "enet_predictions = pd.Series(enet.predict(test_this),\n",
    "                             name='Elastic Net')\n",
    "p_df = pd.DataFrame({'Enet Prediction': enet_predictions,\n",
    "                     'Actual': test_target.values})\n",
    "\n",
    "pylab.figure(figsize=(10, 10))\n",
    "sns.jointplot('Actual', 'Enet Prediction', data=p_df, kind=\"hex\",\n",
    "              color=sns.color_palette()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "metrics_report(mean_predictions, median_predictions, lr_predictions, enet_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##Let's do a RandomForest too. \n",
    "\n",
    "##Because why not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "estimator = RandomForestRegressor()\n",
    "\n",
    "parameters = {'n_estimators': (5, 10, 15, 20),\n",
    "              'min_samples_split': (4, 8, 16),\n",
    "              'min_samples_leaf': (1, 2, 4),\n",
    "             }\n",
    "rfr = GridSearchCV(estimator, parameters, verbose=2, n_jobs=4)\n",
    "rfr.fit(train_this, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rfr_predictions = pd.Series(rfr.predict(test_this),\n",
    "                            name='Random Forest')\n",
    "\n",
    "p_df = pd.DataFrame({'RF Prediction': test_predictions,\n",
    "                     'Actual': test_target.values})\n",
    "\n",
    "pylab.figure(figsize=(10, 10))\n",
    "sns.jointplot('Actual', 'RF Prediction', data=p_df, kind=\"hex\",\n",
    "              color=sns.color_palette()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "metrics_report(mean_predictions,\n",
    "               median_predictions,\n",
    "               lr_predictions,\n",
    "               enet_predictions,\n",
    "               rfr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##These models seem very close\n",
    "###Are they doing anything differently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "lr_diffs = lr_predictions - test_target\n",
    "lr_diffs.name = 'LinearRegression Error'\n",
    "rfr_diffs = rfr_predictions - test_target\n",
    "rfr_diffs.name = 'RandomForest Error'\n",
    "\n",
    "sns.jointplot(lr_diffs, rfr_diffs, kind='hex', color=sns.color_palette()[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###They are making the same kinds of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "###Not unexpected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Feature Engineering (lite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simple transformations\n",
    "### Quadratic combinations of existing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "degree = 2\n",
    "\n",
    "model = make_pipeline(PolynomialFeatures(degree), Lasso())\n",
    "model.fit(train_this, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "poly_preds = pd.Series(model.predict(test_this),\n",
    "                       name='Polynomial Lasso',\n",
    "                       index=test_target.index)\n",
    "\n",
    "\n",
    "sns.jointplot(test_target, \n",
    "              poly_preds,\n",
    "              kind='hex',\n",
    "              color=sns.color_palette()[5])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "metrics_report(mean_predictions,\n",
    "               median_predictions,\n",
    "               lr_predictions,\n",
    "               enet_predictions,\n",
    "               rfr_predictions,\n",
    "               poly_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#What next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##Try more variables\n",
    "##Try different transforms\n",
    "##Ask lots of questions\n",
    "###See where you end up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#Exercise 3\n",
    "\n",
    "##Make a model that gets a better MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Wrap up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##Pandas is great for manipulating data\n",
    "##Matplotlib and Seaborn make sweet visualizations\n",
    "##Scikit-Learn has great ML tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#Thanks for coming!\n",
    "##Enjoy ODSC!\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
